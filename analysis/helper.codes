 var df = spark.sql("select * from avangrid_dev.notification")
 df = df.filter("notification_dt='2018-06-01'")
 var df_over_vol = df.filter ("notification_description = 'Diagnostic 7 Over Voltage, Phase A'")
  var df_end_over_vol_over_vol = df.filter("notification_description = 'Diagnostic 7 Condition Cleared'")
  var df_over_ = df_over_vol.join(df_end_over_vol_over_vol, df_over_vol(col("device_id")) <=> df_end_over_vol_over_vol(col("device_id")) && df_end_over_vol_over_vol(col("notification_time")) > df_over_vol(col("notification_time")))
  var df_event = df_over_vol.join(df_end_over_vol, df_over_vol(col("device_id")) <=> df_end_over_vol(col("device_id")) && df_end_over_vol(col("notification_time")) > df_over_vol(col("notification_time")),"left")
   var df_event = df_start.join(df_end, df_start("device_id") <=> df_end("device_id") && df_end("notification_time") > df_start("notification_time"),"left")
  
  df_event.count
   df_event.show(100,false)
   df_event.printSchema
   df_event.groupby(notification_description,start_time,start_device_id).minimum(end_time).show
   df_event.groupBy("notification_description","start_time","start_device_id").agg(min("end_time"))
   df_event.orderBy("start_device_id","start_time").show(100,false)